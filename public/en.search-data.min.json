[{"id":0,"href":"/","title":"Codes","parent":"","content":""},{"id":1,"href":"/post/odds-ratio-forest-plot/odds-ratio-forest-plot/","title":"Odds Ratio Forest Plot","parent":"Posts","content":" Odds ratios from logistic models are often present using forest plots. Given the coefficients of logistic models are exponentiated to obtain the odds ratios, odds ratios are NOT symmetric on a linear scale. For example,A change from an odds ratio between 0.4 and 0.5 is the same relative change (25% increase) as that between 2.0 and 2.5. But on the linear scale the difference is 0.1 and 0.5 respectively. An odds ratio between 0-1 indicates a decrease of odds, while an odds ratio greater than 1 indicates an increase in odds. The standard errors of odds ratio will also be misleading when plotting on a linear scale. Although looking at an x-axis in log scale may not be intuitive, it’s a much fair visualization on a log scale when you may compare odds ratio across different risk factors in the forest plot.\nlibrary(ggplot2) # Create labels boxLabels = c(\u0026quot;year\u0026quot;, \u0026quot;age X10\u0026quot;, \u0026quot;hct\u0026quot;, \u0026quot;race (black vs. caucasion)\u0026quot;, \u0026quot;bsa (1.6-1.8 vs. \u0026lt;1.6)\u0026quot;, \u0026quot;bsa (1.8-2.0 vs. \u0026lt;1.6)\u0026quot;, \u0026quot;bsa (\u0026gt;=2.0 vs. \u0026lt;1.6)\u0026quot;, \u0026quot;Gender (female vs. male)\u0026quot;, \u0026quot;diabetes\u0026quot;, \u0026quot;PVD\u0026quot;, ) # you may enter odds ratio and 95% CL either option1:manually or options2: reading in data; # option1: Enter summary data. boxOdds are the odds ratios (calculated elsewhere), boxCILow is the lower bound of the CI, boxCIHigh is the upper bound. df \u0026lt;- data.frame( yaxis = length(boxLabels):1, boxOdds = c(1.012,1.252,0.954,1.497,0.826,0.882,1.164,1.07), boxCILow = c(0.966,1.181,0.943,1.258,0.619,0.666,0.871,0.941), boxCIHigh = c(1.06,1.327,0.965,1.781,1.103,1.167,1.555,1.217) ) ## option2: insert the odds ratio data; df=read.csv(\u0026quot;S:/CardiacSurg/Restricted/MSTCVS/Ting MSTCVS/race aki/oddsratio plot.csv\u0026quot;,header=T,sep=\u0026#39;,\u0026#39;) df$yaxis=length(df$boxLabels):1 # Plot p \u0026lt;- ggplot(df, aes(x = boxOdds, y = yaxis)) # using geom_vline to add reference line for odds ratio=1; p + geom_vline(aes(xintercept = 1), size = .25, linetype = \u0026quot;dashed\u0026quot;) + geom_errorbarh(aes(xmax = boxCIHigh, xmin = boxCILow), size = .5, height = .2, color = \u0026quot;gray50\u0026quot;) + geom_point(size = 3.5, color = \u0026quot;orange\u0026quot;) + theme_bw() + theme(panel.grid.minor = element_blank()) + scale_y_continuous(breaks = df$yaxis, labels = df$boxLabels) + scale_x_continuous(breaks = seq(0,7,0.5) ) + #using log scale for the x axis coord_trans(x = \u0026quot;log10\u0026quot;) + ylab(\u0026quot;\u0026quot;) + xlab(\u0026quot;Odds ratio (log scale)\u0026quot;) + annotate(geom = \u0026quot;text\u0026quot;, y =1.1, x = 3, label =\u0026quot;\u0026quot;, size = 3.5, hjust = 0) + ggtitle(\u0026quot;Odds ratios for AKI stage 2-3\u0026quot;) "},{"id":2,"href":"/post/","title":"Posts","parent":"Codes","content":""},{"id":3,"href":"/post/power-linear-regression-model/simulation-to-calculate-power-in-linear-regression-model/","title":"Use simulation to calculate power in linear regression model","parent":"Posts","content":" Simple power calculations can be done through PROC POWER in SAS. Simulation methods can provide more flexibility in calculating the power of estimates of interest. what we know is the estimated effect size from pilot analysis based on existing data or prior literature effect size. To vary the effect size given we never know the true effect size, we may calculate the statistical powers for increasing or decreasing 5% of the “estimated” effect size. Be cautious to not to calculate post hoc power, it’s not meaningful to calculate statistical powers for an effect with a known p value.\n#### use similation to calculate the power in linear regression model############### library(\u0026#39;plyr\u0026#39;) library(\u0026#39;ggplot2\u0026#39;) # the simulation function; regression_sim \u0026lt;- function(simNum, n, b0, b1, b2, b3,b4,b5, b6, b7, b8,b9,b10, err_mean=0, err_sd=74.45294) { # simulate the dummy variables for hospital admission acuity: status1=elective, status2=urgent; status3=emergent; status1 \u0026lt;- sample( 0:1, n, replace=TRUE, prob=c(0.27, 0.73) ) status2 \u0026lt;- sample( 0:1, n, replace=TRUE, prob=c(0.95, 0.05) ) status3 \u0026lt;- sample( 0:1, n, replace=TRUE, prob=c(0.79, 0.21) ) # simulate the dummy variables for euroscore risk score strata euroscore3c1 \u0026lt;- sample( 0:1, n, replace=TRUE, prob=c(0.67, 0.33) ) euroscore3c2 \u0026lt;- sample( 0:1, n, replace=TRUE, prob=c(0.67, 0.33) ) euroscore3c3 \u0026lt;- sample( 0:1, n, replace=TRUE, prob=c(0.67, 0.33) ) # simulate the continous variable team familiairty with estimated mean and std; fourfam \u0026lt;- rnorm(n, mean=23.8, sd=12.1) # the model # generate the outcome y based on the equation; y \u0026lt;- b0 + (b1 * fourfam) + (b2 * status1)+(b3 * status2)+(b4* status3)+ (b5 * euroscore3c1)+(b6 * euroscore3c2)+(b7* euroscore3c3)+ (b8 *fourfam* euroscore3c1)+b9 *fourfam* euroscore3c2+b10 *fourfam* euroscore3c3+ +rnorm(n, mean=err_mean, sd=err_sd) # fun the model with simulation data; model \u0026lt;- lm(y ~ fourfam +status1+status2+status3+euroscore3c1+euroscore3c2+euroscore3c3+ fourfam* euroscore3c1+fourfam* euroscore3c2+fourfam* euroscore3c3) output \u0026lt;- summary(model)$coefficients # identify the coefficients for the interaction terms; # look at the power of detecting team familiarity effect on euroscore strata 1, which will be the sum of #the coefficients of team familairty and the interaction term for team familiarity and euroscore strata 1. # use the delta methods to calculate the variance variance=vcov(model)[2,2]+vcov(model)[9,9]+2*vcov(model)[2,9] # build the wald test; stat= (output[2, 1]+output[9, 1]-0 )/sqrt(variance) # obtain p value; p_values\u0026lt;- 2*pnorm(-abs(stat)) return(p_values) } regression_sim num_sims \u0026lt;- 1000 # repeat the function for 1000 simulation for sample size=1000; # the values for coefficients: b0-b10, the mean and std errors are obtained based on a pilot study on existing data. # to obtain a certain effect, one may vary the effect by increasing or decreasing 5% of the estimated effect. sims \u0026lt;- ldply(1:num_sims, regression_sim, n=1000, b0=226.0049100, b1=-2.5294683, b2=0.0000000, b3=-2.5636306, b4=36.0413179,b5=-78.3913251, b6=-42.9765322, b7=0.0000000, b8=1.5820389, b9=1.2321387, b10=0.0000000, err_mean=0, err_sd=74.45294) # calculate the power. The probability of rejecting the null hypothesis given the alternative hypothesis is true power \u0026lt;- sum(sims \u0026lt; .05) / nrow(sims) # calculate power for various sample sizes; sample_sizes \u0026lt;- c(1000,2000, 3000, 4000, 5000) results \u0026lt;- NULL for (val in sample_sizes) { sims \u0026lt;- ldply(1:100, regression_sim, n=val, b0=226.0049100, b1=-2.5294683, b2=0.0000000, b3=-2.5636306, b4=36.0413179,b5=-78.3913251, b6=-42.9765322, b7=0.0000000, b8=1.5820389, b9=1.2321387, b10=0.0000000, err_mean=0, err_sd=74.45294) sims$n \u0026lt;- val # add the sample size in as a separate column to our results results \u0026lt;- rbind(results, sims) } # conflict between plyr and dplyr. detach plyr, and use library dplyr detach(\u0026quot;package:plyr\u0026quot;, unload=TRUE) library(\u0026#39;dplyr\u0026#39;) # summary the power for various sample size; power_ests \u0026lt;- results %\u0026gt;% group_by(n) %\u0026gt;% summarize(power=sum(V1 \u0026lt; .05) /length(n)) # plot the power with different sample size; ggplot(power_ests, aes(x=n, y=power)) + geom_point() + geom_line() + ylim(c(0, 1)) + theme_minimal() "},{"id":4,"href":"/categories/","title":"Categories","parent":"Codes","content":""},{"id":5,"href":"/categories/R/","title":"R","parent":"Categories","content":""},{"id":6,"href":"/tags/R-blogdown/","title":"R blogdown","parent":"Tags","content":""},{"id":7,"href":"/tags/","title":"Tags","parent":"Codes","content":""},{"id":8,"href":"/post/blog-down/blog-down/","title":"Using R Blogdown for Site Building","parent":"Posts","content":"It\u0026rsquo;s such a learning experience in setting up a website using github+ terminal + R blogdown + netlify for me. In general, I followed the post from [Alison Hill] (https://alison.rbind.io/post/up-and-running-with-blogdown/).\nA couple of problems have occured and I have searched very hard to resolve them.\n   R crash whenever I tried to open projects in Mac OS system.    Solution: download update R version from (https://www.rstudio.com/products/rstudio/download/). Now I have Rstudio 1.1.463 - Mac OS X in my mac.\n  I don\u0026rsquo;t know how to push the local materials to github.    Solution: It seems there are several ways to push local files to github. In R I follow the path Tools \u0026gt; Version Control \u0026gt; git. Then I select the folders that I would like to upload to github. However, some of the folders were NOT staged. In another word, I could not select these Not staged files in order to commit and push them to github.\nTo go around this, I used terminal. In terminal, I used cd to go to the local github clone file. Then I used command git add -A . All files in the folders were able to upload to github then.\n  I could not publish my sites in netlify.    After uploading all neccessary needed files into github, especially the \u0026lsquo;public\u0026rsquo; folder, I followed the deploy setting but failed. The key step here turn out to be that you need to make sure that the hugo versions are consistent in your machine and netlify.\nIn terminal, I typed in `` Hugo versoins` to obtain the hugo versions 0.51 in my machine. In netlify, I added the variables in the deploy setting, Hugo_version, and set the value of 0.51.\n  Create a new post option 1: use addins \u0026lt; NewPost\u0026gt; which will create a newpost under the folder Content/Post option 2: create a Post folder under Content/Post    Insert an image in RMD file and show it in blogdown    option 1: use addins during the edits of .md file This will generate a code in the file for example\n![](/post/2019-03-27-median-survival-time_files/survivalpost1.png) The file directory is under static/ with the relative directory path\noption 2: put the file in the corresponding post file under static/ , and enter the file relative file path. For example, here is another code to add in a image which will allow image size adjustment\nknitr::include_graphics(\u0026quot;/post/2019-03-27-median-survival-time_files/survivalpost2.png\u0026quot;)   use git shell language to push changes Reference: [link] (https://help.github.com/en/articles/adding-an-existing-project-to-github-using-the-command-line)    I did three lines of commands git add . git commit -m \u0026ldquo;change\u0026rdquo; git push -u origin master\n  I was trying to change my themes from academic to a more simple documentation theme. Instead of doing install_theme () which will create many errors during the installation. You may follow the direction https://geekdocs.de/usage/getting-started/ . step1: you may first create a new site in the git clone folder, using new_site () in R, which will use a default theme. step2: install the geekdoc theme in the site folder. You should see geekdoc folder appear in theme folder within the site folder. step 3: you may just change the config.toml to the theme of geekdoc. Then run serve_site().    "},{"id":9,"href":"/about/","title":"About","parent":"Codes","content":"This is a \u0026ldquo;hello world\u0026rdquo; example website for the blogdown package. The theme was forked from @jrutheiser/hugo-lithium-theme and modified by Yihui Xie .\n"},{"id":10,"href":"/post/2015-07-23-r-rmarkdown/","title":"Hello R Markdown","parent":"Posts","content":" R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\nsummary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 fit \u0026lt;- lm(dist ~ speed, data = cars) fit ## ## Call: ## lm(formula = dist ~ speed, data = cars) ## ## Coefficients: ## (Intercept) speed ## -17.579 3.932  Including Plots You can also embed plots. See Figure 1 for example:\npar(mar = c(0, 1, 0, 1)) pie( c(280, 60, 20), c(\u0026#39;Sky\u0026#39;, \u0026#39;Sunny side of pyramid\u0026#39;, \u0026#39;Shady side of pyramid\u0026#39;), col = c(\u0026#39;#0292D8\u0026#39;, \u0026#39;#F7EA39\u0026#39;, \u0026#39;#C4B632\u0026#39;), init.angle = -50, border = NA )  Figure 1: A fancy pie chart.   "},{"id":11,"href":"/tags/plot/","title":"plot","parent":"Tags","content":""},{"id":12,"href":"/tags/R-Markdown/","title":"R Markdown","parent":"Tags","content":""},{"id":13,"href":"/tags/regression/","title":"regression","parent":"Tags","content":""},{"id":14,"href":"/post/PSM/psm/","title":"Propensity score methods-I PS Matching","parent":"Posts","content":" Propensity score methods include 1) propensity score matching; 2) stratification on the propensity score; 3)IPTW: inverse probability of treatment weighting; 4) covariate adjustment using the propensity score. The codes below only apply to propensity score matching.\nVariables considering in the model: To correctly specify the propensity score model, one should include the true confounders (the risk factors that are associated with the ‘treatment’ and outcome) and the potential confounders (the risk facotrs that are associated with the outcome). A safe way to do when sample size is not a concern is to include all baseline risk factors, but this will reduce the matching rate expecially when sample size is small.\n To check balance of propensity score matched sample, one should use standardized difference. A threshold of less than 10% of standardized difference may be used to consider balancing between treatment and control group. Using p-values to determine balance may be discouraged given that 1)p-values are sensitive to sample size. 2) p values are inference from a “superpopulation”, the balance is an attribute to the particular matched sample. One could calculate the standardized difference with the following codes, or use the following formula.\n  The standardized difference for a continous variable is\n\\[ d= \\frac {\\overline{x}_{treatment}-\\overline{x}_{control}}{\\sqrt {\\frac{s^2_{treatment}+s^2_{control}}{2}}} \\]\nThe standardized difference for a binary variable is\n\\[ d=\\frac {\\hat{p}_{treatment}-\\hat{p}_{control}}{\\sqrt {\\frac{\\hat{p}_{treatment} (1-\\hat{p}_{treatment})+ \\hat{p}_{control} (1-\\hat{p}_{control})}{2}}} \\]\n\\[\\alpha \\] \\[\\cos\\left(2\\theta\\right)=\\cos^2\\theta-\\ \\] ^{2 }\nReference: Peter C. Austin.An Introduction to Propensity Score Methods for Reducing the Effects of Confounding in Observational Studies.\nOutcome analyis after matching  3.1 After you obtain a matched sample and verify the balancing of the two treatment groups of interest, you may proceed to outcome analysis using the matched data. Some suggest that conditional logistic model or paired t-tests would be needed to account for pairs, while others suggest conditional on pairs is not necessary for the analysis given the matched sample mimics the randomized trial data. In a daily analysis, usual regression model or tests can be performed without accounting for the matching pairs.\n3.2 one to various ratio matching\nWhen one control is matching to many treatments, and the ratio is not constant, for example, 1:2, 1:1, 1:4 were all possible matching ratio. The outcome analysis tests need to be weighted by the number of controls. For example, if one treatment is matched to 4 controls, each control should be weighted as 1/4. The analysis codes are often needed a weight statement as shown below in 4.1 code example.\nImplementation  4.1 A Sas procedure: SAS psmatch procedure provides convienient implementation for these PS methods, the output also quantifies the standardized difference. Here is an code example.\n4.2. STATA: STATA provide psmatch2, teffects command. The output has ATT, ATE calculated. The command is simple and straightforward, but it is difficult to customize to meet additional analytic need, such as extracting the matched data.\n4.3 A SAS macro: The below uses a SAS macro to find matching samples. The pros of using this extensive macro code is that it allows you to modify the matching criterials. For example, if one wants to do matching within a same center, you may modify the macro matching condition.\n/*using the logistic model to build propensity score model for having autologous blood (variable: autoblood) /*(autologous blood is done before cardiac surgery to collect the patients own blood); * rename autoblood as the treatment group; data dat; set dat; group=AutoBlood; run; * assign the subject id; data dat; set dat; subject_id=_n_;run; * the propensity score model for treatment group; proc logistic data=dat descending outest=betas; class gender CAD_ Any_RF_Preop AcuteStroke PriorCardSx cardiogenicShock severe_AI /param=ref ; model AutoBlood (event=\u0026#39;1\u0026#39;)= age_at_operation BMI RFHemoglobin_ gender AcuteStroke PriorCardSx cardiogenicShock ; *output the dataset \u0026quot;predic\u0026quot; which have predprob: predprob is the probability scale, and xbeta is the linear predictor; output out=predic p=predprob xbeta=logit; run; * if using the probability scale as the propensity score to do matching, then using predprob as the pscoreT/C; * if using the logit scale as the propensity score for matching, then using xbeta as the pscoreT/C; data treatment(rename =(subject_id=idT logit= pscoreT ) );set predic; where group=1 ; run; data control (rename =(subject_id=idC logit= pscoreC) ); set predic; where group=0; run; * using the propensity score matching macro; %include \u0026#39;xx\\propensity score matching macro\\psmatching.sas\u0026#39;; proc means data=predic; var logit; output out=stddata (keep =std) std=std;run; * using the 0.1 standardard deviation of the propensity score as the caliper for finding matching; data stddata; set stddata; caliper=0.1*std;run; *one-to-one matching, no replacement, caliper matching; %PSMatching(datatreatment= treatment, datacontrol= control, method= CALIPER, numberofcontrols=1, caliper=0.0844, replacement= no, out= caliper_matches2); data treatment2 (keep=idT rename=(idT=MatchedToTreatID) ); set treatment;run; data control2 (keep=idC rename=(idC=IdSelectedControl )); set control;run; proc sort data=caliper_matches2 nodupkey out=test2; by MatchedToTreatID;run; * create the data for matching sample; data caliper_pairs; set caliper_matches2; subject_id = IdSelectedControl; pscore = PScoreControl; pair = _N_; output; subject_id = MatchedToTreatID; pscore = PScoreTreat; pair = _N_; output; keep subject_id pscore pair;run; * merging the dataset with the original sample to have the other covariates; proc sort data=dat; by subject_id;run; proc sort data=caliper_pairs; by subject_id;run; data merge_pairs; merge caliper_pairs (in=a) dat (in=b); by subject_id; if a=1 and b=1;run; *check balance for continuous variables by plotting the empirical distribution between treatment and control groups ; proc npar1way d edf plots=edfplot data=merge_pairs scores=data; class group; var pscore age_at_operation BMI RFHemoglobin_ ; run; proc sort data=merge_pairs; by group;run; proc means data=merge_pairs mean median p25 p75; var age_ pre_op_creatinine ef__pre_; class group; run; * MACRO: use standardized difference for checking balance for binary variables; %macro binary (var=, label=); proc means data=merge_pairs mean noprint; var \u0026amp;var; by group; output out=outmean (keep=group mean ) mean=mean ; run; data del0; set outmean; if group=0; mean_0 =mean; keep mean_0;run; data del1; set outmean; if group=1; mean_1 =mean; keep mean_1;run; data newdata; length label $25; merge del0 del1; d= (mean_1-mean_0)/sqrt ((mean_1*(1-mean_1)+mean_0*(1-mean_0))/2); d=round(abs(d),0.0001); label=\u0026amp;label; keep d label; run; proc append data=newdata base=standiff (keep=d label) force;run; %mend binary; proc sort data=merge_pairs; by group;run; * make sure the variables were coded as numeric variables; data merge_pairs; set merge_pairs; if gender=\u0026quot;1\u0026quot; then gender_=1; else gender_=0;run; %binary (var=gender_, label=\u0026quot;gender\u0026quot;) %binary (var=CAD_, label=\u0026quot;CAD_\u0026quot;) %binary (var=severe_AI, label=\u0026quot;severe_AI\u0026quot;) proc print data=standiff;run; * using the matching samples, look at outcome difference with the conditional logistic model; proc logistic data=merge_pairs; class group (ref=\u0026#39;0\u0026#39;); model OperativeMortality (event=\u0026#39;1\u0026#39;)=group; strata pair; run; * using the matching samples, look at survival difference with cox model accounting for the pairs; proc phreg data=merge_pairs ; class group (ref=\u0026#39;0\u0026#39;) pair; model time_since_surgery*death (0)=group; random pair; hazardratio group/diff=ref; run; The below is the propensity score matching MACRO :\n#SAS Macro for obtaining propensity score matching samples; /************************************************ PSmatching.sas adapted from Paper 185-2007 SAS Global Forum 2007 Local and Global Optimal Propensity Score Matching Marcelo Coca-Perraillon Health Care Policy Department, Harvard Medical School, Boston, MA ------------------------------- Treatment and Control observations must be in separate datasets such that Control data includes: idC = subject_id, pscoreC = propensity score Treatment data includes: idT, pscoreT id must be numeric method = NN (nearest neighbor), caliper, or radius caliper value = max for matching replacement = yes/no whether controls can be matched to more than one case out = output data set name example call: %PSMatching(datatreatment= T, datacontrol= C, method= NN, numberofcontrols= 1, caliper=, replacement= no, out= matches); Output format: Id Matched Selected PScore To PScore Obs Control Control TreatID Treat 1 18628 0.39192 16143 0.39192 2 18505 0.23029 16158 0.23002 3 15589 0.29260 16112 0.29260 All other variables discarded. Reformat for merge on subject_id with original data: data pairs; set matches; subject_id = IdSelectedControl; pscore = PScoreControl; pair = _N_; output; subject_id = MatchedToTreatID; pscore = PScoreTreat; pair = _N_; output; keep subject_id pscore pair; ************************************************/ %macro PSMatching(datatreatment=, datacontrol=, method=, numberofcontrols=, caliper=, replacement=, out=); /* Create copies of the treated units if N \u0026gt; 1 */; data _Treatment0(drop= i); set \u0026amp;datatreatment; do i= 1 to \u0026amp;numberofcontrols; RandomNumber= ranuni(12345); output; end; run; /* Randomly sort both datasets */ proc sort data= _Treatment0 out= _Treatment(drop= RandomNumber); by RandomNumber; run; data _Control0; set \u0026amp;datacontrol; RandomNumber= ranuni(45678); run; proc sort data= _Control0 out= _Control(drop= RandomNumber); by RandomNumber; run; data Matched(keep = IdSelectedControl PScoreControl MatchedToTreatID PScoreTreat); length pscoreC 8; length idC 8; /* Load Control dataset into the hash object */ if _N_= 1 then do; declare hash h(dataset: \u0026quot;_Control\u0026quot;, ordered: \u0026#39;no\u0026#39;); declare hiter iter(\u0026#39;h\u0026#39;); h.defineKey(\u0026#39;idC\u0026#39;); h.defineData(\u0026#39;pscoreC\u0026#39;, \u0026#39;idC\u0026#39;); h.defineDone(); call missing(idC, pscoreC); end; /* Open the treatment */ set _Treatment; %if %upcase(\u0026amp;method) ~= RADIUS %then %do; retain BestDistance 99; %end; /* Iterate over the hash */ rc= iter.first(); if (rc=0) then BestDistance= 99; do while (rc = 0); /* Caliper */ %if %upcase(\u0026amp;method) = CALIPER %then %do; if (pscoreT - \u0026amp;caliper) \u0026lt;= pscoreC \u0026lt;= (pscoreT + \u0026amp;caliper) then do; ScoreDistance = abs(pscoreT - pscoreC); if ScoreDistance \u0026lt; BestDistance then do; BestDistance = ScoreDistance; IdSelectedControl = idC; PScoreControl = pscoreC; MatchedToTreatID = idT; PScoreTreat = pscoreT; end; end; %end; /* NN */ %if %upcase(\u0026amp;method) = NN %then %do; ScoreDistance = abs(pscoreT - pscoreC); if ScoreDistance \u0026lt; BestDistance then do; BestDistance = ScoreDistance; IdSelectedControl = idC; PScoreControl = pscoreC; MatchedToTreatID = idT; PScoreTreat = pscoreT; end; %end; %if %upcase(\u0026amp;method) = NN or %upcase(\u0026amp;method) = CALIPER %then %do; rc = iter.next(); /* Output the best control and remove it */ if (rc ~= 0) and BestDistance ~=99 then do; output; %if %upcase(\u0026amp;replacement) = NO %then %do; rc1 = h.remove(key: IdSelectedControl); %end; end; %end; /* Radius */ %if %upcase(\u0026amp;method) = RADIUS %then %do; if (pscoreT - \u0026amp;caliper) \u0026lt;= pscoreC \u0026lt;= (pscoreT + \u0026amp;caliper) then do; IdSelectedControl = idC; PScoreControl = pscoreC; MatchedToTreatID = idT; PScoreTreat = pscoreT; output; end; rc = iter.next(); %end; end; run; /* Delete temporary tables. Quote for debugging */ proc datasets; delete _:(gennum=all); run; data \u0026amp;out; set Matched; run; %mend PSMatching; "}]